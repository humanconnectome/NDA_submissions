{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook updates the 2.0 crosswalk with known issue fixes, new (ndar subjects) variables, drops free text fields, and merges in latest NDA annotation.  Adds KSADS and SSAGA, too, time allowing. Waiting on NDA for the latter...to finish validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, datetime\n",
    "import csv\n",
    "import sys\n",
    "import shutil\n",
    "from openpyxl import load_workbook\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from scipy import stats\n",
    "from ccf.box import LifespanBox\n",
    "from ccf.config import LoadSettings\n",
    "from ccf.redcap import RedcapTable \n",
    "config = LoadSettings()\n",
    "from ccf.easy_yaml import EasyYaml\n",
    "Y = EasyYaml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#box=LifespanBox(cache='./cache/')\n",
    "#verbose = True\n",
    "snapshotdate = datetime.datetime.today().strftime('%m_%d_%Y')\n",
    "preppedA=\"./prepped/hca\"\n",
    "preppedD=\"./prepped/hcd\" \n",
    "toolA=\"/home/petra/NIHToolbox2NDA/prepped/HCA\"\n",
    "toolD=\"/home/petra/NIHToolbox2NDA/prepped/HCD\" \n",
    "pathout=\".\"\n",
    "\n",
    "#Rosetta (a.k.a Inventory) file will have all the nda vars and pedids\n",
    "#extrainfo=config['rosetta']['filename']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the 2.0 dictionary,drop all nda dd stuff except for element and structure name so that new\n",
    "\n",
    "#C2=pd.read_csv(\"./Crosswalk_Lifespan_Behavioral_2.0_01_12_2021.csv\")\n",
    "CD=pd.read_excel(\"./LS2.0_Crosswalk_Behavioral_Data_Dictionary.xlsx\",sheet_name='C-2846 (HCP-D)')\n",
    "CA=pd.read_excel(\"./LS2.0_Crosswalk_Behavioral_Data_Dictionary.xlsx\",sheet_name='C-2847 (HCP-A)')\n",
    "print(CD.shape)\n",
    "print(CA.shape)\n",
    "C2=pd.concat([CD,CA],axis=0)\n",
    "print(C2.shape)\n",
    "C2.collection.value_counts()\n",
    "C2=C2.drop(columns=['nda_description','nda_notes','nda_range','nda_structure_link'])\n",
    "C2.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the header for all prepared structures for list of mapped elements\n",
    "elems=[]\n",
    "structures=[]\n",
    "colls=[]\n",
    "for preps in [preppedA,preppedD]:# do toolbox stuff later,toolA,toolD]:\n",
    "    if preps==preppedA:\n",
    "        collection='C-2847 (HCP-A)'\n",
    "    if preps==preppedD:\n",
    "        collection='C-2846 (HCP-D)'\n",
    "    for filename in os.listdir(preps):\n",
    "        if 'ssaga' not in filename:\n",
    "            if 'ksads' not in filename:\n",
    "                print(filename)\n",
    "                addem=pd.read_csv(preps+'/'+filename,header=1,nrows=0).columns.tolist()\n",
    "                l=len(addem)\n",
    "                m=filename.replace('.csv','')\n",
    "                if 'eprime' in filename:\n",
    "                    m='deldisk01'\n",
    "                structs=[m]*l\n",
    "                collects=[collection]*l\n",
    "                elems=elems+addem\n",
    "                structures=structures+structs\n",
    "                colls=colls+collects\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InPrepped=pd.DataFrame({'nda_element':elems,'nda_structure':structures,'collection':colls})\n",
    "InPrepped.head(2)\n",
    "len(InPrepped.nda_structure.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#toolbox\n",
    "elems=[]\n",
    "structures=[]\n",
    "colls=[]\n",
    "for preps in [toolA,toolD]:\n",
    "    if preps==toolA:\n",
    "        collection='C-2847 (HCP-A)'\n",
    "    if preps==toolD:\n",
    "        collection='C-2846 (HCP-D)'\n",
    "    for filename in os.listdir(preps):\n",
    "        addem=pd.read_csv(preps+'/'+filename,header=1,nrows=0).columns.tolist()\n",
    "        #gender/sex aliases all messed up here and at NDA\n",
    "        addem = [word.replace('gender','sex') for word in addem]\n",
    "        struc=pd.read_csv(preps+'/'+filename,header=0,nrows=0).columns.tolist()\n",
    "        m=struc[0]+'01'\n",
    "        l=len(addem)\n",
    "        #m=filename.replace('.csv','')\n",
    "        structs=[m]*l\n",
    "        collects=[collection]*l\n",
    "        elems=elems+addem\n",
    "        structures=structures+structs\n",
    "        colls=colls+collects\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InPreppedT=pd.DataFrame({'nda_element':elems,'nda_structure':structures,'collection':colls})\n",
    "InPreppedT.head(5)\n",
    "len(InPreppedT.nda_structure.unique())\n",
    "' '.join(i for i in list(InPreppedT.nda_structure.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate toolbox with non toolbox\n",
    "InPrepped=pd.concat([InPrepped,InPreppedT],axis=0)\n",
    "len(InPrepped.nda_structure.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop any vars that were excluded in 3.0 (e.g. notes text, etc), by merging the 2.0 \n",
    "#with the InPrepped\n",
    "C3init=pd.merge(C2,InPrepped,how='outer',on=['nda_element','nda_structure','collection'],indicator=True)\n",
    "C3init._merge.value_counts()\n",
    "\n",
    "#these will need to be found and patched in:\n",
    "C3init.loc[C3init._merge=='right_only'].to_csv('onlyinprepped.csv',index=False)\n",
    "\n",
    "#helper files for creating patch:\n",
    "patchlist=['flanker01','orrt01','prang01','preda01','predd01','psm01','self_effic01','tlbx_emsup01','tlbx_friend01','tlbx_rej01','tlbx_sadness01','tlbx_wellbeing01','tpvt01']\n",
    "#subset existing crosswalk to structure of interest to facilitate copy/paste\n",
    "patchtlbx=C3init.loc[(C3init._merge=='right_only') & (C3init.nda_structure.isin(patchlist))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load the TLBX annotation and reconfigure so it can be used to patch holes for new tlbx elements\n",
    "crosswalkpath=\"/home/petra/NIHToolbox2NDA/\"\n",
    "cfile=\"Crosswalk_NIH_Toolbox_2_NDA.csv\"\n",
    "crosswalk=pd.read_csv(crosswalkpath+cfile,header=0,low_memory=False, encoding = \"ISO-8859-1\")\n",
    "crosswalk=crosswalk.drop(columns=['Measurement System','validated','DataType','specialty_code','template','inst_short','Source','description','valueRange','notes'])\n",
    "\n",
    "crosswalk=crosswalk.loc[crosswalk.nda_structure.isin(patchlist)]\n",
    "crosswalk=crosswalk.rename(columns={'Responses':'hcp_choices_calcs','Inst':'hcp_instrument','hcp_variable':'hcp_variable_name',\n",
    "                          'action_requested':'nda_request','requested_python':'trans_func','description':'nda_description',\n",
    "                                    'valueRange':'nda_range','notes':'nda_notes','Source':'hcp_source'})\n",
    "\n",
    "crosswalk['hcp_label']=crosswalk['Domain'].fillna('') +\":\"+ crosswalk['Item ID'].fillna('') +\":\"+ crosswalk['Stem'].fillna('') +\":\"+ crosswalk['Context'].fillna('')\n",
    "crosswalk['hcp_label']=crosswalk['hcp_label'].str.strip(\":\")\n",
    "crosswalk.loc[crosswalk.hcp_label.fillna('')=='','hcp_label']=crosswalk.hcp_variable_name \n",
    "crosswalk=crosswalk.drop(columns=['Domain','Item ID','Stem','Context'])\n",
    "                                  \n",
    "crosswalk['source']='NIH Toolbox'\n",
    "crosswalk=crosswalk.loc[crosswalk.nda_element.isnull()==False]\n",
    "crosswalk.columns\n",
    "crosswalk['hcp_description']=''\n",
    "crosswalk['trans_nda_request']=''\n",
    "crosswalk['hcp_source']=''\n",
    "\n",
    "#another helper file for creating patch:\n",
    "toolboxpatch=pd.merge(patchtlbx[['collection','nda_element','nda_structure']],\n",
    "        crosswalk[['nda_element','nda_structure','hcp_description','hcp_source','hcp_variable_name','hcp_label','hcp_instrument','hcp_choices_calcs',\n",
    "           'trans_nda_request','trans_func']],on=['nda_element','nda_structure'],how='left')\n",
    "toolboxpatch.to_csv('patchtest.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load patch (created offline from list of elements in prepped only and fleshed out with stuff from tlbx, etc)\n",
    "C3=pd.merge(C2,InPrepped,how='inner',on=['nda_element','nda_structure','collection'])\n",
    "patch=pd.read_csv(\"./CrosswalkPatch.csv\")\n",
    "print(C3.shape)\n",
    "patch.shape\n",
    "print(C3.columns)\n",
    "print(patch.columns)\n",
    "\n",
    "C4=pd.concat([C3,patch],axis=0)\n",
    "\n",
    "#add in the in-scanner facename variables, even though they aren't ready for 3.0 distro\n",
    "C4=C4.loc[~(C4.nda_structure=='facename01')]\n",
    "face=C2.loc[C2.nda_structure=='facename01']\n",
    "C4new=pd.concat([C4,face],axis=0)\n",
    "\n",
    "#cleanup\n",
    "C4=C4new.drop(columns=['nda_aliases','nda_description','nda_notes','nda_range','nda_structure_link'])\n",
    "\n",
    "#double check that C4 has everything needed in terms of maps \n",
    "C4init=pd.merge(C4,InPrepped,how='outer',on=['nda_element','nda_structure','collection'],indicator=True)\n",
    "C4init.loc[C4init._merge=='right_only'].to_csv('onlyinprepped.csv',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add ssaga and ksads...use the NDA data dictionary for these structures\n",
    "ssaga1=pd.read_csv(preppedA+'/ssaga_part101.csv',header=1,nrows=0).columns.tolist()\n",
    "Ssaga1=pd.DataFrame(ssaga1)\n",
    "Ssaga1['nda_structure']='ssaga_part101'\n",
    "\n",
    "ssaga2=pd.read_csv(preppedA+'/ssaga_part201.csv',header=1,nrows=0).columns.tolist()\n",
    "Ssaga2=pd.DataFrame(ssaga2)\n",
    "Ssaga2['nda_structure']='ssaga_part201'\n",
    "\n",
    "Ssaga=pd.concat([Ssaga1,Ssaga2],axis=0)\n",
    "Ssaga['collection']='C-2847 (HCP-A)'\n",
    "Ssaga.columns=['nda_element','nda_structure','collection']\n",
    "\n",
    "Ssaga.head()\n",
    "Ssaga.nda_structure.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ksads=pd.read_csv(preppedD+'/hcpksads01.csv',header=1,nrows=0).columns.tolist()\n",
    "Ksads=pd.DataFrame(ksads)\n",
    "Ksads['nda_structure']='hcpksads01'\n",
    "Ksads['collection']='C-2847 (HCP-D)'\n",
    "Ksads.columns=['nda_element','nda_structure','collection']\n",
    "Ksads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put it all together\n",
    "C5=pd.concat([C4,Ssaga,Ksads])\n",
    "len(C5.nda_structure.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure all the rosetta vars look good.\n",
    "C5.loc[C5.hcp_source=='rosetta','hcp_instrument']='Inventory'\n",
    "# add SSAGA and KSADS, and double check that all TLBX vars are present, since some\n",
    "# might not have made it to first crosswalk due to smaller sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge fresh NDA information and then flesh out Ksads and SSaga 'hcp_source','hcp_description' and 'values'.\n",
    "#drop harmonized harmonization_index\n",
    "C5.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the NDA maps\n",
    "nda = {}\n",
    "for filename in os.listdir('./nda/'):\n",
    "    struct = filename[:-5]\n",
    "    elements = Y('./nda/'+filename)\n",
    "    nda[struct] = elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structs=[]\n",
    "for i in nda.keys():\n",
    "    structs=structs+[i]\n",
    "\n",
    "type(structs)\n",
    "len(structs)\n",
    "#structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structs=[]\n",
    "for i in nda.keys():\n",
    "    structs=structs+[i]\n",
    "    c=pd.DataFrame()\n",
    "\n",
    "for j in structs:\n",
    "    #print(j)\n",
    "    a=pd.DataFrame.from_dict(nda[j])\n",
    "    b=a.transpose()\n",
    "    b=b.reset_index()\n",
    "    b['nda_structure']=j\n",
    "    c=pd.concat([c,b])\n",
    "    \n",
    "\n",
    "c.nda_structure.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=c.rename(columns={'index':'nda_element','description':'nda_description','range':'nda_range',\n",
    "                  'notes':'nda_notes','alias':'nda_aliases'})\n",
    "d['nda_structure_link']='https://nda.nih.gov/data_structure.html?short_name='+c['nda_structure']\n",
    "d=d.drop(columns=['type','required','length','codes','condition'])\n",
    "d.columns\n",
    "d=d[['nda_element','nda_description', 'nda_notes','nda_range', 'nda_aliases', \n",
    "       'nda_structure']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(d.nda_structure.unique())\n",
    "d.nda_element.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.head(2)\n",
    "d.nda_element\n",
    "d.nda_structure\n",
    "d.loc[d.nda_structure=='ipaq01'].head()\n",
    "C5.loc[C5.nda_structure=='ipaq01'].head()\n",
    "C5.nda_structure.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosswalk=pd.merge(C5,d,how='left',on=['nda_structure','nda_element'])\n",
    "crosswalk['nda_structure_link']='https://nda.nih.gov/data_structure.html?short_name='+crosswalk['nda_structure']\n",
    "crosswalk.nda_structure.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crosswalk.loc[crosswalk.collection.str.contains('([sup_1_y]:[sup_7_y])')]\n",
    "#crosswalk.loc[crosswalk.collection.str.contains('; Validation: All items must be answered')]\n",
    "#C-2846 (HCP-D)\tsup_y_ss_sum\tgbi01\t7UP sum of all Validation: All items must be answered\tteen/child\ts7upchildself_sum\t7UP sum of all Validation: All items must be answered\tup_scores:The 7 Up Inventory\tif([s7upchildself_nm]>=1, \"NaN\", sum([s7upchildself1], [s7upchildself2], [s7upchildself3], [s7upchildself4], [s7upchildself5], [s7upchildself6], [s7upchildself7]))\t\t\t\t\tSTRUCTURE MISMATCH\t102346\t\t7UP sum\n",
    "#([sup_1_y]:[sup_7_y])\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "#; Validation: All items must be answered\t\t\ts7upchildself_sum\thttps://nda.nih.gov/data_structure.html?short_name=gbi01\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "#crosswalk.loc[crosswalk.collection=='C-2846 (HCP-D)'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosswalk.to_csv('Crosswalk_Lifespan_3.0.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NDAsubmissions_venv",
   "language": "python",
   "name": "ndasubmissions_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
