{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funcs import funcs\n",
    "from Crosswalk.Transformer import Transformer\n",
    "from Crosswalk.DataCache import DataCache\n",
    "from Crosswalk.NDAWriter import NDAWriter\n",
    "from Crosswalk.Manager import Manager\n",
    "\n",
    "from Crosswalk.Loader import BoxLoader, SsagaLoader, QintLoader, RedcapLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create folder for prepped structures, if it doesn't exist\n",
    "!!mkdir prepped\n",
    "!!mkdir prepped/hca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note the path to the validator below.  This is the vtcmd.py validator written by the NDA.  \n",
    "# If you haven't already installed this, please do so now: https://github.com/NDAR/nda-tools\n",
    "# and the place the path that shows up when you type 'which vtcmd' from your terminal\n",
    "# validation results will be sent to and read from whatever default is specified in the vtcmd configuration file,\n",
    "# so if you're using vtcmd to validate any other datatypes, keep this in mind.\n",
    "\n",
    "M = Manager(\n",
    "        data =  DataCache(\n",
    "            RedcapLoader('hcpa'),\n",
    "#             SsagaLoader(),\n",
    "            QintLoader()\n",
    "        ),\n",
    "        writer = NDAWriter(completed_dir=\"./prepped/hca/\", validator=\"/home/petra/.local/bin/vtcmd\"),\n",
    "        #writer = NDAWriter(completed_dir=\"./prepped/hca/\"),\n",
    "        transformer = Transformer(funcs = funcs, map_dir='./maps/hca/')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timing:  hcpa 5.2811431884765625\n",
      "Timing:  qint 0.12752175331115723\n"
     ]
    }
   ],
   "source": [
    "# This step requires that you have a 'rosetta stone' file that has all the required NDA fields for \n",
    "# all subjects you intend to submit at this time.  This approach facilitates keeping track of subject counts\n",
    "# across data types.  For example, if your required fields are already stored in XNAT because you had the CCF\n",
    "# upload your imaging data for you, you can export this csv from XNAT and rename as appropriate.  \n",
    "# Place this file at the main level of this repository, or redirect the read_csv path in the \n",
    "# Loader.py program's _post_load_hook_ method referenced below.  the method is currently hardcoded to read this csv and rename \n",
    "# columns to NDA requirements of ['subject', 'subjectkey', 'gender', 'interview_date', 'interview_age']\n",
    "# as follows.  \n",
    "        #rosetta = pd.read_csv('UnrelatedHCAHCD_w_STG_Image_and_pseudo_GUID05_05_2020.csv')\n",
    "        #rosetta = rosetta[['subjectped', 'nda_guid', 'nda_gender', 'nda_interview_date', 'nda_interview_age']]\n",
    "        #rosetta.columns = ['subject', 'subjectkey', 'gender', 'interview_date', 'interview_age']\n",
    "#future versions of this code will pull out this file into config.py or even better place, if demand warrants.\n",
    "#For now, just tweak this function to read your own rosetta file, making sure to result in csv with required, or\n",
    "# fill out the template file and save it as 'UnrelatedHCAHCD_w_STG_Image_and_pseudo_GUID05_05_2020.csv'\n",
    "\n",
    "M.preload_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For struct \"leap01\": \n",
      "lan3err: Invalid values  {105.0, 118.0}\n",
      "Dropping 2 values.\n",
      "No errors!\n"
     ]
    }
   ],
   "source": [
    "M.run(\"leap01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For struct \"asr01\": \n",
      "No errors!\n",
      "For struct \"batbil01\": \n",
      "No errors!\n",
      "For struct \"bsc01\": \n",
      "No errors!\n",
      "For struct \"drugscr01\": \n",
      "No errors!\n",
      "For struct \"gales01\": \n",
      "No errors!\n",
      "For struct \"ipaq01\": \n",
      "No errors!\n",
      "For struct \"lbadl01\": \n",
      "No errors!\n",
      "For struct \"mchq01\": \n",
      "No errors!\n",
      "For struct \"medh01\": \n",
      "No errors!\n",
      "For struct \"mendt01\": \n",
      "No errors!\n",
      "For struct \"moca01\": \n",
      "No errors!\n",
      "For struct \"nffi01\": \n",
      "No errors!\n",
      "For struct \"psqi01\": \n",
      "No errors!\n",
      "For struct \"ravlt01\": \n",
      "No errors!\n",
      "For struct \"scan_debrief01\": \n",
      "No errors!\n"
     ]
    }
   ],
   "source": [
    "# The commented out structs are for SSAGA, which was held back at the time this code was last run.  \n",
    "#implemented in section below \n",
    "structs = [\n",
    "    'asr01',\n",
    "    'batbil01',\n",
    "    'bsc01',\n",
    "#     'diagpsx01',\n",
    "    'drugscr01',\n",
    "#     'eatdisdemo01',\n",
    "    'gales01',\n",
    "    'ipaq01',\n",
    "    'lbadl01',\n",
    "#     'leap01',\n",
    "    'mchq01',\n",
    "    'medh01',\n",
    "    'mendt01',\n",
    "    'moca01',\n",
    "    'nffi01',\n",
    "#     'phenx_sib01',\n",
    "    'psqi01',\n",
    "    'ravlt01',\n",
    "    'scan_debrief01',\n",
    "#     'scidv_pscyh01',\n",
    "#     'socdem01'\n",
    "  ]\n",
    "\n",
    "for s in structs:\n",
    "    M.run(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSAGA and not mapped at this time because NDA wanted to reconsider how they organize this info per 5/1/20 email.  \n",
    "structs = [\n",
    "#     'diagpsx01',\n",
    "#     'eatdisdemo01',\n",
    "#     'phenx_sib01',\n",
    "#     'scidv_pscyh01',\n",
    "#     'socdem01'\n",
    "  ]\n",
    "\n",
    "for s in structs:\n",
    "    M.run(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NDA_submissions_venv",
   "language": "python",
   "name": "nda_submissions_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
