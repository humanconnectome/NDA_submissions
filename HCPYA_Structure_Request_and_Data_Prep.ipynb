{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6abc0ac4",
   "metadata": {},
   "source": [
    "## Notebook to take HCP-YA Behavioral data dictionary and corresponding data and request a new structure and reshape data for NDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df11579a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re, datetime\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e6c9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the data dictionary downloaded from IntraDB\n",
    "dictionya=pd.read_csv('CanonicalDataDictionaryCSV.csv', encoding = 'ISO-8859-1')\n",
    "print(dictionya.shape)\n",
    "dictionya=dictionya.drop_duplicates(subset='columnHeader')\n",
    "print(dictionya.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d6b95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize NDA data dictionary variables for structure request and crosswalk. Note that we have to keep YAElement for Element because there will\n",
    "#distinct from NDA element, due to variable name length restrictions in the latter and ndar_subjects requirements\n",
    "dictionya['YAElement']=dictionya.columnHeader\n",
    "dictionya['Required']='Recommended'\n",
    "dictionya['Data Type']=dictionya.dictType\n",
    "dictionya['nda_description']=dictionya.description\n",
    "dictionya['Notes']=dictionya['values']\n",
    "dictionya['Size']=''\n",
    "dictionya['Value Range']=dictionya['values']\n",
    "dictionya.loc[dictionya.description.isnull()==True,'nda_description']=dictionya.fullDisplayName\n",
    "dictionya['hcp_description']=dictionya.nda_description\n",
    "dictionya.loc[dictionya.dictType=='$','Data Type']='Float'\n",
    "dictionya.loc[dictionya['Data Type']=='Boolean','Data Type']='String'\n",
    "\n",
    "#fix one incorrect datatype\n",
    "dictionya.loc[dictionya['YAElement']=='Correction','Data Type']='Float'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfa2eca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load data fieldnames from data so we can \n",
    "#subset to fields that are available for download on IntraDB:\n",
    "#keep 5 subjects' data so that we can see the format when spot checking output\n",
    "\n",
    "d1=pd.read_csv('data/RESTRICTED_plenzini_3_22_2022_11_34_54.csv',nrows=5)\n",
    "d2=pd.read_csv('data/unrestricted_plenzini_3_22_2022_11_34_38.csv',nrows=5)\n",
    "d3=pd.read_csv('data/unrestricted_plenzini_3_22_2022_11_35_0.csv',nrows=5)\n",
    "d=pd.concat([d1.transpose(),d2.transpose(),d3.transpose()],axis=0)\n",
    "d=d.reset_index()\n",
    "print(d.shape)\n",
    "d=d.drop_duplicates() #three Age bucketing variables from different sources\n",
    "print(d.shape)\n",
    "d=d.rename(columns={'index':'YAElement'})\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a0532f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge together for intersection of datadictionary elements and data elements\n",
    "#there shouldn't be any duplicates because we already got rid of the duplicate 'Age' bucket variables (not needed because NDA uses age in months anyway)\n",
    "\n",
    "a=pd.merge(dictionya,d,on='YAElement',how='right')\n",
    "print(a.shape)\n",
    "a.head()\n",
    "#a.columns\n",
    "a.loc[a.YAElement=='Age_in_Yrs']\n",
    "a=a.drop_duplicates(subset='YAElement')\n",
    "print(a.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099dc1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#patch notes and values, since this is faster than parsing all of the exceptions to trends\n",
    "patch=pd.read_csv('ValuePatch.csv', encoding = 'ISO-8859-1')\n",
    "updated = a.merge(patch, how='left', on=['YAElement'], suffixes=('', '_new'))\n",
    "updated['Value Range'] = np.where(pd.notnull(updated['Value Range_new']), updated['Value Range_new'], updated['Value Range'])\n",
    "updated['Notes'] = np.where(pd.notnull(updated['Notes_new']), updated['Notes_new'], updated['Notes'])\n",
    "updated=updated.loc[~(updated.YAElement=='Age')]\n",
    "updated.loc[updated.Notes=='_','Notes']==''\n",
    "#updated[['Value Range','Notes']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e534d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#these will be converted to NDA variables during data manipulation.  Right now we're just preparing crosswalk\n",
    "#so don't need them (they'll get added in mandatory variables part next).\n",
    "updated=updated.loc[~(updated.YAElement.isin(['Aquisition','Age_in_Yrs','Gender','Subject','subjectkey']))]#=updated.loc[~(updated.Element=='Age')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbbb9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trim YA element names for NDA (need to be 30 characters)\n",
    "#replacements\n",
    "updated['Element']=updated.YAElement\n",
    "\n",
    "subs={'Weekday':'Wkdy',\n",
    "    'Weekend':'Wknd',\n",
    "    'Cooler':'Cool',\n",
    "    'Language':'Lang',\n",
    "    'anteriorcingulate':'antcingul',\n",
    "    'Gambling':'Gamb',\n",
    "    'Median':'Med',\n",
    "   'Smaller':'Small',\n",
    "   'Larger':'Lrg',\n",
    "   'Difficulty':'Diffic',\n",
    "   'Level':'Lvl',\n",
    "   'Tobacco':'Tob',\n",
    "   'Random':'Rand',\n",
    "   'Nontarget':'NTarg',\n",
    "   'Target':'Targ'                                        \n",
    "   }\n",
    "\n",
    "for word, abbrev in subs.items():\n",
    "    updated['Element'] = updated.Element.str.replace(word,abbrev)\n",
    "\n",
    "updated['shortelemstrlength']=updated.Element.str.len()\n",
    "print(\"any element strings >30?\")\n",
    "print(updated.loc[updated.shortelemstrlength>30])\n",
    "\n",
    "#check that you didnt create non-unique variable name by comparing Ns\n",
    "print(updated.shape)\n",
    "print(len(updated.Element.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47502085",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the NDA fields (adding them to crosswalk...the rename/reformat in the data itself will happen later)\n",
    "structuremandatory1=pd.DataFrame({'YAElement':['nda_guid','Subject','Aquisition','Age_in_Yrs','Gender','dummy8'],\n",
    "                                 'Element': ['subjectkey','src_subject_id','interview_date','interview_age','sex','race'], \n",
    "                                 'Required': ['Required','Required','Required','Required','Required','Required'],\n",
    "                                 'Data Type': ['GUID','String','Date','Integer','String','String'],\n",
    "                                 'Size': ['','20','','','20','30'],\n",
    "                                 'hcp_description':['Pseudo GUID',\"HCP Subject ID\",'Aquisition Quarter converted to Date. MM/DD/YYYY','Age in Years converted to Age in months','Sex of subject at birth','Mandatory NDA categories for race of study subject.  See HCPYA_Race in hcpya01 structure instead'],\n",
    "                                 'nda_description':['The NDAR Global Unique Identifier (GUID) for research subject',\"Subject ID how it's defined in lab/project\",'Date on which the interview/genetic test/sampling/imaging/biospecimen was completed. MM/DD/YYYY','Age in months at the time of the interview/test/sampling/imaging.','Sex of subject at birth','Race of study subject'],\n",
    "                                 'Value Range':['NDAR*','','','0 :: 1260','M;F; O; NR',''],  \n",
    "                                 'Notes':['','','','','','']})\n",
    "\n",
    "structuremandatory2=pd.DataFrame({'YAElement':['dummy1','dummy2','dummy3','dummy4','dummy5','dummy6','dummy7'],\n",
    "                                  'Element':['phenotype','phenotype_description','twins_study','sibling_study','family_study','comments_misc','sample_taken'],\n",
    "                                  'Required': ['Required','Required','Required','Required','Required','Required','Required'],\n",
    "                                  'Data Type':['String','String','String','String','String','String','String'],\n",
    "                                  'hcp_description':['hardcoded dummy variable','hardcoded dummy variable','hardcoded dummy variable','hardcoded dummy variable','hardcoded dummy variable','hardcoded dummy variable','hardcoded dummy variable'],\n",
    "                                  'nda_description':['Phenotype/diagnosis for the subject','Description of the phenotype for the subject','Is this study of twins?','Was it sibling study? Study of sibling(s) of autistic child.','Was it family study? Study of biological mother, biological father and/or sibling of proband','Miscellaneous comments on study, interview, methodology relevant to this form data','Was a sample taken at this interview/during this project time'],\n",
    "                                  'Notes':['','','','','','',''],\n",
    "                                  'Value Range':['','','','','','','']\n",
    "                                                })\n",
    "#'dummy1':'phenotype',\n",
    "#'dummy2':'phenotype_description',\n",
    "#'dummy3':'twins_study',\n",
    "#'dummy4':'sibling_study',\n",
    "#'dummy5':'family_study'}\n",
    "#'dummy6':'comments_misc'\n",
    "#'dummy7':'sample_taken'\n",
    "\n",
    "structuremandatory=pd.concat([structuremandatory1,structuremandatory2],axis=0)\n",
    "#structuremandatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f6cfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is not really the final crosswalk...misnomer...sorry\n",
    "final=pd.concat([structuremandatory,updated[['Required','hcp_description','nda_description','Element','YAElement','Data Type','Size','Notes','Value Range','Value Range_new','Notes_new',0,1,2,3,4]]],axis=0)#\n",
    "final.head(20)\n",
    "#inttypes=list(final.loc[final['Data Type']=='Integer'])\n",
    "a=final.loc[final['Data Type']=='Integer'][['YAElement']]\n",
    "inttypes=list(a['YAElement'])\n",
    "#inttypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84b42b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to map YAElement to Element in crosswalk\n",
    "#note that Race (HCP) is not the same as race (nda)\n",
    "#replace strings\n",
    "renames={\n",
    "'ZygosityGT':'zygosity',\n",
    "'Family_ID':'family_user_def_id',\n",
    "'Mother_ID':'src_mother_id',\n",
    "'Father_ID':'src_father_id',\n",
    "'Ethnicity':'ethnic_group'}\n",
    "\n",
    "for word, abbrev in renames.items():\n",
    "    final.loc[final.YAElement==word,'Element']=abbrev\n",
    "\n",
    "#'ZygositySR' doesn't have a place ndar subjects so it will have to show up in the main table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16eb3669",
   "metadata": {},
   "outputs": [],
   "source": [
    "final=final.rename(columns={'Element':'Element Name'})\n",
    "\n",
    "#create the rename list for prepping the data itself later\n",
    "renames4NDA=dict(zip(final.YAElement,final['Element Name']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6df6069",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now prep data to match dictionary\n",
    "#load data  fields that are available for download on IntraDB and will go:\n",
    "d1=pd.read_csv('data/RESTRICTED_plenzini_3_22_2022_11_34_54.csv')\n",
    "d2=pd.read_csv('data/unrestricted_plenzini_3_22_2022_11_34_38.csv')\n",
    "d3=pd.read_csv('data/unrestricted_plenzini_3_22_2022_11_35_0.csv')\n",
    "d2=d2.drop(columns=['Age'])\n",
    "for i in list(d3.columns)+list(d2.columns)+list(d1.columns):\n",
    "    if 'Age' in i:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abadd50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataraw=pd.merge(d1,d2,on='Subject',how='inner')\n",
    "dataraw=pd.merge(dataraw,d3,on='Subject',how='inner')\n",
    "dataraw.shape\n",
    "dataraw=dataraw.rename(columns={'Subject':'src_subject_id','Gender':'sex'})\n",
    "dataraw['interview_age']=dataraw['Age_in_Yrs']*12\n",
    "\n",
    "dataraw.loc[dataraw.Acquisition=='Q01','interview_date']='08/01/2012'\n",
    "dataraw.loc[dataraw.Acquisition=='Q02','interview_date']='11/01/2012'\n",
    "dataraw.loc[dataraw.Acquisition=='Q03','interview_date']='02/01/2013'\n",
    "dataraw.loc[dataraw.Acquisition=='Q04','interview_date']='05/01/2013'\n",
    "dataraw.loc[dataraw.Acquisition=='Q05','interview_date']='08/01/2013'\n",
    "dataraw.loc[dataraw.Acquisition=='Q06','interview_date']='11/01/2013'\n",
    "dataraw.loc[dataraw.Acquisition=='Q07','interview_date']='02/01/2014'\n",
    "dataraw.loc[dataraw.Acquisition=='Q08','interview_date']='05/01/2014'\n",
    "dataraw.loc[dataraw.Acquisition=='Q09','interview_date']='08/01/2014'\n",
    "dataraw.loc[dataraw.Acquisition=='Q10','interview_date']='11/01/2014'\n",
    "dataraw.loc[dataraw.Acquisition=='Q11','interview_date']='02/01/2015'\n",
    "dataraw.loc[dataraw.Acquisition=='Q12','interview_date']='05/01/2015'\n",
    "dataraw.loc[dataraw.Acquisition=='Q13','interview_date']='08/01/2015'\n",
    "\n",
    "dataraw['interview_date']=pd.to_datetime(dataraw['interview_date']).dt.strftime('%m/%d/%Y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56299416",
   "metadata": {},
   "outputs": [],
   "source": [
    "#makes sure inttypes are int types (according to how NDA reads these which is actually a string)\n",
    "#first double check that type wasn't incorrectly assigned\n",
    "dataraw[inttypes].to_csv('testints.csv',index=False)\n",
    "\n",
    "for i in inttypes:\n",
    "    try:\n",
    "        dataraw[i]=dataraw[i].round().fillna(-9999).astype(int).astype(str).str.replace('-9999','')\n",
    "    except:\n",
    "        print('problem with',i)\n",
    "    \n",
    "dataraw=dataraw.drop(columns=['Age_in_Yrs'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594edd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns to match NDA elements\n",
    "dataraw=dataraw.rename(columns=renames4NDA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b707216",
   "metadata": {},
   "outputs": [],
   "source": [
    "#not renamed yet\n",
    "dataraw.Race.value_counts()\n",
    "\n",
    "#not created yet\n",
    "#dataraw.race.value_counts()\n",
    "\n",
    "#annotation\n",
    "final.loc[final['Element Name']=='Race']\n",
    "\n",
    "#not added yet\n",
    "#final.loc[final['Element Name']=='race']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cba92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(final['Element Name']):\n",
    "    if i not in list(dataraw.columns): \n",
    "        print('in annotation only:',i)\n",
    "        \n",
    "for i in list(dataraw.columns):\n",
    "    if i not in list(final['Element Name']): \n",
    "        print('in data only:',i)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951675f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add psuedoguids (subjectkey) to data\n",
    "pseudos=pd.read_csv('data/hcpya_guid_list.csv')\n",
    "pseudos.columns=['src_subject_id','subjectkey']\n",
    "pseudos.head()\n",
    "\n",
    "alldata=pd.merge(pseudos,dataraw,on='src_subject_id',how='right',indicator=True)\n",
    "print(alldata._merge.value_counts())\n",
    "alldata=alldata.drop(columns=['_merge'])\n",
    "\n",
    "#dataraw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd87feee",
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210f6eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#condition comments_misc on HasGT and race on Race\n",
    "alldata['comments_misc']=''\n",
    "alldata.loc[alldata.HasGT==True,'comments_misc']=\"Genotypes were derived from saliva and/or whole blood and uploaded to dbGAP under GUID identifiers\"\n",
    "\n",
    "alldata.HasGT.value_counts()\n",
    "alldata.comments_misc.value_counts()\n",
    "\n",
    "#races are not coded the same across databases\n",
    "alldata['race']=alldata.replace({'Race':\n",
    "                                       {'Am. Indian/Alaskan Nat.':'American Indian/Alaska Native',\n",
    "                                        'Black or African Am.':'Black or African American',\n",
    "                                        'White':'White',\n",
    "                                        'Asian/Nat. Hawaiian/Othr Pacific Is.':'More than one race',\n",
    "                                        'More than one':'More than one race',\n",
    "                                        'Unknown or Not Reported':'Unknown or not reported'}})['Race']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb2ce55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#############################\n",
    "#race (NDA) and Race are not the same\n",
    "#rename Race to make it clear that Race comes from HCP\n",
    "#############################\n",
    "print(alldata.Race.value_counts())\n",
    "print(alldata.race.value_counts())\n",
    "\n",
    "final.loc[final['YAElement']=='Race','Element Name']='HCPYA_Race'\n",
    "alldata=alldata.rename(columns={'Race':'HCPYA_Race'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f3eb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "newstructure=alldata.drop(columns=['race','ethnic_group',\n",
    "       'zygosity', 'family_user_def_id', 'src_mother_id', 'src_father_id','comments_misc'])\n",
    "print('#variables in new structure:',len(newstructure.columns))\n",
    "#write out csv for validation\n",
    "filePath='HCPYA_prepped/hcpya01.csv'\n",
    "\n",
    "if os.path.exists(filePath):\n",
    "    os.remove(filePath)\n",
    "else:\n",
    "    print(\"Can not delete the file as it doesn't exists\")\n",
    "\n",
    "with open(filePath,'a') as f:\n",
    "    f.write(\"hcpya01,1\\n\")\n",
    "    newstructure.to_csv(f,index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd1c8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#move  race ethnic_group to ndar_subject01\n",
    "#separate into ndar subjects and all other data\n",
    "ndar=alldata[['src_subject_id', 'subjectkey','interview_date','interview_age','sex','race','ethnic_group', \n",
    "       'zygosity', 'family_user_def_id', 'src_mother_id', 'src_father_id','comments_misc']].copy()\n",
    "\n",
    "\n",
    "ndar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e28d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndar.race.value_counts() #different from HCP race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba4e91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndar.loc[:,'phenotype']=pd.Series((\"Healthy Subject\" for i in range(ndar.shape[0])),index=ndar.index)\n",
    "ndar.loc[:,'phenotype_description']=pd.Series((\"No diagnosed history of neurologic or major psychiatric disorder\" for i in range(ndar.shape[0])),index=ndar.index)\n",
    "ndar.loc[:,'twins_study']=pd.Series((\"No\" for i in range(ndar.shape[0])),index=ndar.index)\n",
    "ndar.loc[:,'sibling_study']=pd.Series((\"No\" for i in range(ndar.shape[0])),index=ndar.index)\n",
    "ndar.loc[:,'family_study']=pd.Series((\"No\" for i in range(ndar.shape[0])),index=ndar.index)\n",
    "ndar.loc[:,'sample_taken']=pd.Series((\"No\" for i in range(ndar.shape[0])),index=ndar.index)\n",
    "\n",
    "ndar=ndar.rename(columns={'Family_ID':'family_user_def_id','Father_ID':'src_father_id','Mother_ID':'src_mother_id'})\n",
    "\n",
    "\n",
    "\n",
    "ndar['zygosity']=ndar.replace({'zygosity':\n",
    "                                     {'MZ':'monozygous',\n",
    "                                      'DZ':'dizygous'}})['zygosity']\n",
    "\n",
    "#ethnicities are not coded the same across databases\n",
    "ndar['ethnic_group']=ndar.replace({'ethnic_group':\n",
    "                                           {'Hispanic/Latino':'Hispanic or Latino',\n",
    "                                            'Not Hispanic/Latino':'Not Hispanic or Latino',\n",
    "                                            'Unknown or Not Reported':'unknown or not reported'}})['ethnic_group']\n",
    "\n",
    "\n",
    "list(ndar.columns)\n",
    "ndar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec684d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write out csv for validation\n",
    "filePath='HCPYA_prepped/ndar_subject01.csv'\n",
    "print(\"#variables in ndar_subjects:\",len(ndar.columns))\n",
    "\n",
    "if os.path.exists(filePath):\n",
    "    os.remove(filePath)\n",
    "else:\n",
    "    print(\"Can not delete the file as it doesn't exists\")\n",
    "\n",
    "with open(filePath,'a') as f:\n",
    "    f.write(\"ndar_subject,1\\n\")\n",
    "    ndar.to_csv(f,index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae91e84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up the crosswalk and assign structures.  \n",
    "#then finalize the new structure request variable subset\n",
    "crosswalk=final.drop(columns=[0,1,2,3,4])\n",
    "#assign crosswalk elements to structures\n",
    "crosswalk['structure']=''\n",
    "crosswalk.loc[crosswalk['Element Name'].isin(list(ndar.columns)),'structure']='ndar_subject'\n",
    "crosswalk.loc[crosswalk['Element Name'].isin(['src_subject_id','subjectkey', 'interview_date', 'interview_age', 'sex']),'structure']='All Structures'\n",
    "crosswalk.loc[crosswalk['structure']=='','structure']='hcpya01'\n",
    "\n",
    "crosswalk.loc[crosswalk['Element Name'].isin(['Race','ethnic_group']),'Notes']=''\n",
    "crosswalk.loc[crosswalk['Notes']=='_','Notes']=''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a38a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "crosswalk.structure.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f7c38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set string lengths for data variables (not ndar_subjects or All structures variables)\n",
    "b=crosswalk.loc[(crosswalk['Data Type']=='String') & (~(crosswalk.structure.isin(['ndar_subject','All Structures']))) ][['Element Name']]\n",
    "print('b size:',b.shape)\n",
    "strvars=list(b['Element Name'])\n",
    "\n",
    "#strvars=list(crosswalk.loc[crosswalk['Data Type']=='String'][['Element Name']])\n",
    "mx_dct = {c: newstructure[c].map(lambda x: len(str(x))).max() for c in strvars}\n",
    "varlengths=pd.Series(mx_dct).sort_values(ascending =False)\n",
    "v=pd.DataFrame(varlengths.reset_index())\n",
    "v.columns=['Element Name','newlength']\n",
    "v.head()\n",
    "v['newlength']=v.newlength/10\n",
    "v['newlength']=10*v.newlength.apply(np.ceil).astype('Int64')\n",
    "v.head()\n",
    "crosswalk=crosswalk.merge(v,how='left', on=['Element Name'])\n",
    "crosswalk.columns\n",
    "crosswalk.loc[(crosswalk.newlength.isnull()==False) & (crosswalk['Data Type']=='String'),'Size']=crosswalk.newlength\n",
    "crosswalk=crosswalk.drop(columns=['Value Range_new','Notes_new','newlength'])\n",
    "#crosswalk.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19558f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "crosswalk.to_csv(\"HCP_YA_Crosswalk.csv\",index=False)\n",
    "print(\"number of elements in crosswalk:\",crosswalk.shape[0])\n",
    "crosswalk.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9109eb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "newstructurerequest=crosswalk.loc[~(crosswalk['Element Name'].isin(['race','ethnic_group', 'comments_misc', \n",
    "       'zygosity', 'family_user_def_id', 'src_mother_id', 'src_father_id','phenotype','phenotype_description',\n",
    "                                'twins_study','sibling_study','family_study','sample_taken']))].drop(columns=['structure','YAElement','hcp_description'])\n",
    "newstructurerequest.shape\n",
    "\n",
    "newstructurerequest=newstructurerequest.rename(columns={'nda_description':'Description'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccef038f",
   "metadata": {},
   "outputs": [],
   "source": [
    "newstructurerequest.to_csv(\"hcpya01_structuredef.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181a137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#double check variable counts\n",
    "for i in list(newstructurerequest['Element Name']):\n",
    "    if i not in list(newstructure.columns): \n",
    "        print('in annotation only:',i)\n",
    "        \n",
    "for i in list(newstructure.columns):\n",
    "    if i not in list(newstructurerequest['Element Name']): \n",
    "        print('in data only:',i)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40bd802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec181d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NDA_Submissions",
   "language": "python",
   "name": "nda_submissions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
