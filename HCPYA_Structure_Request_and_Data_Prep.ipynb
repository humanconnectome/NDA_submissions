{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6abc0ac4",
   "metadata": {},
   "source": [
    "## Notebook to take HCP-YA Behavioral data dictionary and corresponding data and request a new structure and reshape data for NDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df11579a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re, datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e6c9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionya=pd.read_csv('CanonicalDataDictionaryCSV.csv')\n",
    "print(dictionya.shape)\n",
    "dictionya=dictionya.drop_duplicates(subset='columnHeader')\n",
    "print(dictionya.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d6b95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename variables as NDA counterparts.\n",
    "dictionya['Element']=dictionya.columnHeader\n",
    "dictionya['Required']='Recommended'\n",
    "dictionya['Data Type']=dictionya.dictType\n",
    "dictionya['Description']=dictionya.description\n",
    "#dictionya['Description']=dictionya['Description'].str.replace(r'<[^<>]*>', '', regex=True)\n",
    "dictionya['Notes']=dictionya['values']\n",
    "dictionya['Size']=''\n",
    "dictionya['Value Range']=dictionya['values']\n",
    "dictionya.loc[dictionya.description.isnull()==True,'Description']=dictionya.fullDisplayName\n",
    "dictionya.loc[dictionya.dictType=='$','Data Type']='Float'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfa2eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data fieldnames from data so we can \n",
    "#subset to fields that are available for download on IntraDB:\n",
    "d1=pd.read_csv('data/RESTRICTED_plenzini_3_22_2022_11_34_54.csv',nrows=5)\n",
    "d2=pd.read_csv('data/unrestricted_plenzini_3_22_2022_11_34_38.csv',nrows=5)\n",
    "d3=pd.read_csv('data/unrestricted_plenzini_3_22_2022_11_35_0.csv',nrows=5)\n",
    "d=pd.concat([d1.transpose(),d2.transpose(),d3.transpose()],axis=0)\n",
    "d=d.reset_index()\n",
    "print(d.shape)\n",
    "d=d.drop_duplicates() #three Age bucketing variables from different sources\n",
    "print(d.shape)\n",
    "d=d.rename(columns={'index':'Element'})\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a0532f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge together for intersection of datadictionary elements and data elements\n",
    "a=pd.merge(dictionya,d,on='Element',how='right')\n",
    "print(a.shape)\n",
    "a.head()\n",
    "#a.columns\n",
    "a.loc[a.Element=='Age_in_Yrs']\n",
    "a=a.drop_duplicates(subset='Element')\n",
    "print(a.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099dc1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#patch notes and values, since this is faster than parsing all of the exceptions to trends\n",
    "patch=pd.read_csv('ValuePatch.csv')\n",
    "updated = a.merge(patch, how='left', on=['Element'], suffixes=('', '_new'))\n",
    "updated['Value Range'] = np.where(pd.notnull(updated['Value Range_new']), updated['Value Range_new'], updated['Value Range'])\n",
    "updated['Notes'] = np.where(pd.notnull(updated['Notes_new']), updated['Notes_new'], updated['Notes'])\n",
    "updated=updated.loc[~(updated.Element=='Age')]\n",
    "updated.loc[updated.Notes=='_','Notes']==''\n",
    "updated[['Value Range','Notes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e534d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#these converted to NDA variables during data manipulation.  Right now we're just preparing data\n",
    "#dictionary so don't need them (they'll get added in mandatory variables part next).\n",
    "updated=updated.loc[~(updated.Element.isin(['Age_in_Yrs','Gender','Subject','subjectkey']))]#=updated.loc[~(updated.Element=='Age')]\n",
    "\n",
    "#more fixes\n",
    "updated.loc[updated['Data Type']=='Boolean','Data Type']='String'\n",
    "#dictionya['Description']=dictionya['Description'].str.replace(r'<[^<>]*>', '', regex=True)\n",
    "#updated.loc[updated.Description.str.contains('Neurolex')]#,'Description']#=updated.fullDisplayName+':'+updated['Description'].str.replace(r'<[^<>]*>', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47502085",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the NDA fields\n",
    "structuremandatory=pd.DataFrame({'Element': ['subjectkey','src_subject_id','interview_date','interview_age','sex'], \n",
    "                                 'Required': ['Required','Required','Required','Required','Required'],\n",
    "                                 'Data Type': ['GUID','String','Date','Integer','String'],\n",
    "                                 'Size': ['','20','','','20'],\n",
    "                                 'Description':['The NDAR Global Unique Identifier (GUID) for research subject',\"Subject ID how it's defined in lab/project\",'Date on which the interview/genetic test/sampling/imaging/biospecimen was completed. MM/DD/YYYY','Age in months at the time of the interview/test/sampling/imaging.','Sex of subject at birth'],\n",
    "                                 'Value Range':['NDAR*','','','0 :: 1260','M;F; O; NR'],  \n",
    "                                 'Notes':['','','','','']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16eb3669",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final=pd.concat([structuremandatory,updated[['Required','Description','Element','Data Type','Size','Notes','Value Range','Value Range_new','Notes_new',0,1,2,3,4]]],axis=0)#\n",
    "#move race and ethnicity to ndar_subjects01\n",
    "final=final.loc[~(final.Element.isin(['Race','Ethnicity']))]\n",
    "\n",
    "final.rename(columns={'Element':'Element Name'}).to_csv(\"HCP_YA_CanonicalDataDictionary.csv\",index=False)\n",
    "\n",
    "print(final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6df6069",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now prep data to match dictionary\n",
    "#load data  fields that are available for download on IntraDB and will go:\n",
    "d1=pd.read_csv('data/RESTRICTED_plenzini_3_22_2022_11_34_54.csv')\n",
    "d2=pd.read_csv('data/unrestricted_plenzini_3_22_2022_11_34_38.csv')\n",
    "d3=pd.read_csv('data/unrestricted_plenzini_3_22_2022_11_35_0.csv')\n",
    "d2=d2.drop(columns=['Age'])\n",
    "#d1=d1.drop(columns=['Age'])\n",
    "#d3=d3.drop(columns=['Age'])\n",
    "\n",
    "#list(d1.columns)\n",
    "for i in list(d3.columns):\n",
    "    if 'Age' in i:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abadd50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataraw=pd.merge(d1,d2,on='Subject',how='inner')\n",
    "dataraw=pd.merge(dataraw,d3,on='Subject',how='inner')\n",
    "dataraw.shape\n",
    "dataraw=dataraw.rename(columns={'Subject':'src_subject_id','Gender':'sex'})\n",
    "dataraw['interview_age']=dataraw['Age_in_Yrs']*12\n",
    "dataraw=dataraw.drop(columns=['Age_in_Yrs'])\n",
    "#print(dataraw.Acquisition.value_counts())\n",
    "dataraw.loc[dataraw.Acquisition=='Q01','interview_date']='08/01/2012'\n",
    "dataraw.loc[dataraw.Acquisition=='Q02','interview_date']='11/01/2012'\n",
    "dataraw.loc[dataraw.Acquisition=='Q03','interview_date']='02/01/2013'\n",
    "dataraw.loc[dataraw.Acquisition=='Q04','interview_date']='05/01/2013'\n",
    "dataraw.loc[dataraw.Acquisition=='Q05','interview_date']='08/01/2013'\n",
    "dataraw.loc[dataraw.Acquisition=='Q06','interview_date']='11/01/2013'\n",
    "dataraw.loc[dataraw.Acquisition=='Q07','interview_date']='02/01/2014'\n",
    "dataraw.loc[dataraw.Acquisition=='Q08','interview_date']='05/01/2014'\n",
    "dataraw.loc[dataraw.Acquisition=='Q09','interview_date']='08/01/2014'\n",
    "dataraw.loc[dataraw.Acquisition=='Q10','interview_date']='11/01/2014'\n",
    "dataraw.loc[dataraw.Acquisition=='Q11','interview_date']='02/01/2015'\n",
    "dataraw.loc[dataraw.Acquisition=='Q12','interview_date']='05/01/2015'\n",
    "dataraw.loc[dataraw.Acquisition=='Q13','interview_date']='08/01/2015'\n",
    "\n",
    "dataraw['interview_date']=pd.to_datetime(dataraw['interview_date']).dt.strftime('%m/%d/%Y')\n",
    "\n",
    "#dataraw.to_csv('test.csv',index=False)\n",
    "#len(d1.Subject.unique())\n",
    "dataraw.sex.head()\n",
    "dataraw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cba92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#only variable left should be subjectkey, which is missing from data because atm \n",
    "#dont know location of pseudoguids\n",
    "\n",
    "for i in list(final['Element']):\n",
    "    if i not in list(dataraw.columns): \n",
    "        print('in annotation only:',i)\n",
    "        \n",
    "for i in list(dataraw.columns):\n",
    "    if i not in list(final['Element']): \n",
    "        print('in data only:',i)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951675f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add psuedoguids (subjectkey) to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd1c8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#move  Race Ethnicity to ndar_subject01\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NDAsubmissions_venv",
   "language": "python",
   "name": "ndasubmissions_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
